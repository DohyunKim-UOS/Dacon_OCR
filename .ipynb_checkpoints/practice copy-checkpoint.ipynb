{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35aa1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import subprocess\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b5fcb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ìƒˆë¡­ê²Œ ì„¤ì¹˜í•´ì•¼ í•  ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "# pip install \"git+https://github.com/lukas-blecher/LaTeX-OCR\"\n",
    "from pix2tex.cli import LatexOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "996725a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ë¡œë”©\n",
    "yolo_model = YOLO(\"./model/yolov11n-doclaynet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2438093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ìƒˆë¡œìš´ ëª¨ë¸\n",
    "equation_model = LatexOCR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37fefbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í´ëž˜ìŠ¤ ë§¤í•‘\n",
    "LABEL_MAP = {\n",
    "    'Text': 'text',\n",
    "    'Title': 'title',\n",
    "    'Section-header': 'subtitle',\n",
    "    'Formula': 'equation',\n",
    "    'Table': 'table',\n",
    "    'Picture': 'image'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c008554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_images(input_path, temp_dir, dpi=200):\n",
    "    ext = Path(input_path).suffix.lower()\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    if ext == \".pdf\":\n",
    "        return convert_from_path(input_path, dpi=dpi, output_folder=temp_dir, fmt=\"png\")\n",
    "    elif ext == \".pptx\":\n",
    "        # Convert pptx to pdf first\n",
    "        subprocess.run([\n",
    "            \"libreoffice\", \"--headless\", \"--convert-to\", \"pdf\", \"--outdir\", temp_dir, input_path\n",
    "        ], check=True)\n",
    "        pdf_path = os.path.join(temp_dir, Path(input_path).with_suffix(\".pdf\").name)\n",
    "        return convert_from_path(pdf_path, dpi=dpi, output_folder=temp_dir, fmt=\"png\")\n",
    "    elif ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        return [Image.open(input_path).convert(\"RGB\")]\n",
    "    else:\n",
    "        raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ìž…ë‹ˆë‹¤: {ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdd60e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_bbox_to_target(bbox, current_size, target_size):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    scale_x = target_size[0] / current_size[0]\n",
    "    scale_y = target_size[1] / current_size[1]\n",
    "    return [\n",
    "        int(x1 * scale_x),\n",
    "        int(y1 * scale_y),\n",
    "        int(x2 * scale_x),\n",
    "        int(y2 * scale_y)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d29a8d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR ì •í™•ë„ ë†’ì´ëŠ” ë°©í–¥ìœ¼ë¡œ ìˆ˜ì • ìš”í•¨\n",
    "def extract_text(image_pil, bbox): \n",
    "    x1, y1, x2, y2 = bbox\n",
    "    cropped = image_pil.crop((x1, y1, x2, y2))\n",
    "    return pytesseract.image_to_string(cropped, lang='kor+eng').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1067bb2",
   "metadata": {},
   "source": [
    "ì´ í•¨ìˆ˜ëŠ” ê°œì„ ì´ í•„ìš”í• ê¹Œ?\n",
    "ì´ í•¨ìˆ˜ëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œì˜ ê¸°ë³¸ ê¸°ëŠ¥ì€ ìž˜ ìˆ˜í–‰í•˜ê³  ìžˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ OCRì˜ ì •í™•ë„ë¥¼ ë†’ì´ë ¤ë©´ ë‹¤ìŒ ë¶€ë¶„ì„ ê°œì„ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "í•´ìƒë„ ìµœì í™”: convert_to_images í•¨ìˆ˜ì—ì„œ dpi ê°’ì„ ì¡°ì •í•˜ë©´ OCR ì •í™•ë„ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, DPIë¥¼ ë†’ì´ë©´ ë” ì„ ëª…í•œ ì´ë¯¸ì§€ë¥¼ ì–»ì–´ ì •í™•ë„ê°€ ë†’ì•„ì§€ì§€ë§Œ, ì²˜ë¦¬ ì†ë„ê°€ ëŠë ¤ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "ì „ì²˜ë¦¬ ê°•í™”: í…ìŠ¤íŠ¸ ì¶”ì¶œ ì „ì— ì´ë¯¸ì§€ì˜ ëŒ€ë¹„(contrast)ë¥¼ ë†’ì´ê±°ë‚˜, ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ëŠ” ë“±ì˜ ì „ì²˜ë¦¬ ìž‘ì—…ì„ ì¶”ê°€í•˜ë©´ OCR ì„±ëŠ¥ì´ ë” ì¢‹ì•„ì§ˆ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ë¥¸ OCR ì—”ì§„ ì‚¬ìš©: pytesseract ì™¸ì— EasyOCRë‚˜ PaddleOCRì™€ ê°™ì€ ë‹¤ë¥¸ OCR ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ ë³´ì„¸ìš”. ì´ë“¤ì€ ê²½ìš°ì— ë”°ë¼ ë” ë†’ì€ ì •í™•ë„ë¥¼ ì œê³µí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê²°ë¡ ì ìœ¼ë¡œ, ì´ í•¨ìˆ˜ëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œì˜ í•µì‹¬ì´ë¯€ë¡œ, OCR ì •í™•ë„ë¥¼ ë†’ì´ëŠ” ë°©í–¥ìœ¼ë¡œ ê°œì„ ì„ ê³ ë ¤í•´ ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27cfb1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ê°œì„ \n",
    "def extract_equation_as_latex(image_pil, bbox):\n",
    "    try:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        cropped_image = image_pil.crop((x1, y1, x2, y2))\n",
    "        \n",
    "        # Pix2Tex ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ LaTeX ì½”ë“œ ì¶”ì¶œ\n",
    "        latex_code = equation_model(cropped_image)\n",
    "        \n",
    "        return f'${latex_code}$'\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ìˆ˜ì‹ ë³€í™˜ ì‹¤íŒ¨: {e}\")\n",
    "        return \"\" # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë¬¸ìžì—´ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2e6c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inference_one_image(id_val, image_pil, target_size, conf_thres=0.3):\n",
    "#     original_size = image_pil.size  # (w, h)\n",
    "#     resized_image = image_pil.resize((1024, 1024))\n",
    "#     temp_path = \"_temp_image.png\"\n",
    "#     resized_image.save(temp_path)\n",
    "\n",
    "#     results = model(source=temp_path, imgsz=1024, conf=conf_thres, verbose=False)[0]\n",
    "#     os.remove(temp_path)\n",
    "\n",
    "#     predictions = []\n",
    "#     order = 0\n",
    "#     for box, score, cls in zip(results.boxes.xyxy, results.boxes.conf, results.boxes.cls):\n",
    "#         label = results.names[int(cls)]\n",
    "#         if label not in LABEL_MAP:\n",
    "#             continue\n",
    "#         category_type = LABEL_MAP[label]\n",
    "#         x1, y1, x2, y2 = scale_bbox_to_target(box.tolist(), (1024, 1024), target_size)\n",
    "#         text = extract_text(image_pil, [x1, y1, x2, y2]) if category_type in ['title', 'subtitle', 'text'] else ''\n",
    "#         predictions.append({\n",
    "#             'ID': id_val,\n",
    "#             'category_type': category_type,\n",
    "#             'confidence_score': score.cpu().item(),\n",
    "#             'order': order,\n",
    "#             'text': text,\n",
    "#             'bbox': f'{x1}, {y1}, {x2}, {y2}'\n",
    "#         })\n",
    "#         order += 1\n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe2f223",
   "metadata": {},
   "source": [
    "ë„¤, ì´ í•¨ìˆ˜ëŠ” ê°€ìž¥ ë§Žì´ ìˆ˜ì •í•˜ê³  ê°œì„ í•´ì•¼ í•  ë¶€ë¶„ìž…ë‹ˆë‹¤. íŠ¹ížˆ ë‹¤ìŒ ë‘ ê°€ì§€ê°€ í•µì‹¬ ê°œì„ ì ìž…ë‹ˆë‹¤.\n",
    "\n",
    "ìˆœì„œ(order) ì˜ˆì¸¡ ë¡œì§:\n",
    "\n",
    "í˜„ìž¬ ì½”ë“œëŠ” order = 0ìœ¼ë¡œ ì‹œìž‘í•˜ì—¬ ë£¨í”„ë¥¼ ëŒ ë•Œë§ˆë‹¤ order += 1ì„ í•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ê²°ê³¼ë¥¼ ë°˜í™˜í•œ ìˆœì„œëŒ€ë¡œ ìˆœìœ„ë¥¼ ë§¤ê¸°ëŠ” ê²ƒìœ¼ë¡œ, ë…¼ë¦¬ì ì¸ ì½ê¸° ìˆœì„œì™€ëŠ” ì•„ë¬´ ê´€ë ¨ì´ ì—†ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê°œì„  ë°©ë²•: ë£¨í”„ê°€ ëë‚œ í›„ predictions ë¦¬ìŠ¤íŠ¸ë¥¼ bbox ì¢Œí‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìž¬ì •ë ¬í•˜ëŠ” ìƒˆë¡œìš´ ë¡œì§ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, y1 ì¢Œí‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬í•˜ê³ , y1ì´ ê°™ì„ ê²½ìš° x1ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ì‹œ ì •ë ¬í•˜ëŠ” ë°©ì‹ì´ ê°€ìž¥ ê¸°ë³¸ì ìž…ë‹ˆë‹¤.\n",
    "\n",
    "ìˆ˜ì‹(equation) ì¶”ì¶œ:\n",
    "\n",
    "í˜„ìž¬ ì½”ë“œì—ëŠ” ìˆ˜ì‹(Formula)ì´ category_typeìœ¼ë¡œëŠ” ì¡´ìž¬í•˜ì§€ë§Œ, textë¥¼ ì¶”ì¶œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê°œì„  ë°©ë²•: category_typeì´ 'equation'ì¼ ë•Œ, textë¥¼ ë¹ˆ ë¬¸ìžì—´('')ë¡œ ë‘ëŠ” ëŒ€ì‹ , extract_text í•¨ìˆ˜ì™€ëŠ” ë³„ê°œë¡œ ìˆ˜ì‹ ì´ë¯¸ì§€ë¥¼ LaTeXë¡œ ë³€í™˜í•˜ëŠ” ìƒˆë¡œìš´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ë¥¼ text í•„ë“œì— ì±„ì›Œ ë„£ì–´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87beb165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ê°œì„ \n",
    "def inference_one_image_improved(id_val, image_pil, target_size, conf_thres=0.5):\n",
    "    original_size = image_pil.size\n",
    "    resized_image = image_pil.resize((1024, 1024))\n",
    "    temp_path = \"_temp_image.png\"\n",
    "    resized_image.save(temp_path)\n",
    "\n",
    "    results = yolo_model(source=temp_path, imgsz=1024, conf=conf_thres, verbose=False)[0]\n",
    "    os.remove(temp_path)\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    # 1. ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì €ìž¥\n",
    "    for box, score, cls in zip(results.boxes.xyxy, results.boxes.conf, results.boxes.cls):\n",
    "        label = results.names[int(cls)]\n",
    "        if label not in LABEL_MAP:\n",
    "            continue\n",
    "        category_type = LABEL_MAP[label]\n",
    "        bbox_scaled = scale_bbox_to_target(box.tolist(), (1024, 1024), target_size)\n",
    "        \n",
    "        # ðŸ’¡ ê°œì„ ëœ ë¡œì§: category_typeì— ë”°ë¼ í•œ ë²ˆë§Œ í˜¸ì¶œ\n",
    "        text = ''\n",
    "        if category_type in ['title', 'subtitle', 'text']:\n",
    "            text = extract_text(image_pil, bbox_scaled)\n",
    "        elif category_type == 'equation':\n",
    "            text = extract_equation_as_latex(image_pil, bbox_scaled, equation_model)\n",
    "        \n",
    "        predictions.append({\n",
    "            'ID': id_val,\n",
    "            'category_type': category_type,\n",
    "            'confidence_score': score.cpu().item(),\n",
    "            'bbox': f'{bbox_scaled[0]}, {bbox_scaled[1]}, {bbox_scaled[2]}, {bbox_scaled[3]}',\n",
    "            'bbox_list': bbox_scaled, \n",
    "            'text': text\n",
    "        })\n",
    "\n",
    "    # 2. ë°”ìš´ë”© ë°•ìŠ¤ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
    "    predictions.sort(key=lambda p: (p['bbox_list'][1], p['bbox_list'][0]))\n",
    "    \n",
    "    # 3. ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ì— 'order' ê°’ ë¶€ì—¬\n",
    "    for i, p in enumerate(predictions):\n",
    "        p['order'] = i\n",
    "        del p['bbox_list']\n",
    "        \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20051429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(test_csv_path=\"./data/test.csv\", output_csv_path=\"./output/submission.csv\"):\n",
    "    output_dir = os.path.dirname(output_csv_path)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    temp_image_dir = \"./temp_images\"\n",
    "    os.makedirs(temp_image_dir, exist_ok=True)\n",
    "\n",
    "    csv_dir = os.path.dirname(test_csv_path)\n",
    "    test_df = pd.read_csv(test_csv_path)\n",
    "    all_preds = []\n",
    "\n",
    "    for _, row in test_df.iterrows():\n",
    "        id_val = row['ID']\n",
    "        raw_path = row['path']\n",
    "        file_path = os.path.normpath(os.path.join(csv_dir, raw_path))\n",
    "        target_width = int(row['width'])\n",
    "        target_height = int(row['height'])\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"âš ï¸ íŒŒì¼ ì—†ìŒ: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            images = convert_to_images(file_path, temp_image_dir)\n",
    "            for i, image in enumerate(images):\n",
    "                full_id = f\"{id_val}_p{i+1}\" if len(images) > 1 else id_val\n",
    "                preds = inference_one_image_improved(full_id, image, (target_width, target_height))\n",
    "                all_preds.extend(preds)\n",
    "            print(f\"âœ… ì˜ˆì¸¡ ì™„ë£Œ: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {file_path} â†’ {e}\")\n",
    "\n",
    "    result_df = pd.DataFrame(all_preds)\n",
    "    result_df.to_csv(output_csv_path, index=False, encoding='UTF-8-sig')\n",
    "    print(f\"âœ… ì €ìž¥ ì™„ë£Œ: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9afe1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert /mnt/c/Users/user/documents/dacon2025samsung/Dacon_OCR/data/test/TEST_00.pptx -> /mnt/c/Users/user/documents/dacon2025samsung/Dacon_OCR/temp_images/TEST_00.pdf using filter : impress_pdf_Export\n",
      "Overwriting: /mnt/c/Users/user/documents/dacon2025samsung/Dacon_OCR/temp_images/TEST_00.pdf\n",
      "âœ… ì˜ˆì¸¡ ì™„ë£Œ: data/test/TEST_00.pptx\n",
      "âœ… ì˜ˆì¸¡ ì™„ë£Œ: data/test/TEST_01.png\n",
      "âœ… ì˜ˆì¸¡ ì™„ë£Œ: data/test/TEST_02.pdf\n",
      "âœ… ì˜ˆì¸¡ ì™„ë£Œ: data/test/TEST_03.jpg\n",
      "âœ… ì €ìž¥ ì™„ë£Œ: ./output/submission.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    inference(\"./data/test.csv\", \"./output/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde3453-fabd-4b1e-a61f-eeb90f3bf4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon2025samsung",
   "language": "python",
   "name": "dacon2025samsung"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
