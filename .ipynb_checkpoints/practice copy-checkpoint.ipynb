{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35aa1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import subprocess\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5fcb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ÏÉàÎ°≠Í≤å ÏÑ§ÏπòÌï¥Ïïº Ìï† ÎùºÏù¥Î∏åÎü¨Î¶¨\n",
    "# pip install \"git+https://github.com/lucas-r/pix2tex.git\"\n",
    "from pix2tex.cli import LatexOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996725a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Î™®Îç∏ Î°úÎî©\n",
    "yolo_model = YOLO(\"./model/yolov11n-doclaynet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2438093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ÏÉàÎ°úÏö¥ Î™®Îç∏\n",
    "equation_model = LatexOCR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37fefbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌÅ¥ÎûòÏä§ Îß§Ìïë\n",
    "LABEL_MAP = {\n",
    "    'Text': 'text',\n",
    "    'Title': 'title',\n",
    "    'Section-header': 'subtitle',\n",
    "    'Formula': 'equation',\n",
    "    'Table': 'table',\n",
    "    'Picture': 'image'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c008554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_images(input_path, temp_dir, dpi=200):\n",
    "    ext = Path(input_path).suffix.lower()\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    if ext == \".pdf\":\n",
    "        return convert_from_path(input_path, dpi=dpi, output_folder=temp_dir, fmt=\"png\")\n",
    "    elif ext == \".pptx\":\n",
    "        # Convert pptx to pdf first\n",
    "        subprocess.run([\n",
    "            \"libreoffice\", \"--headless\", \"--convert-to\", \"pdf\", \"--outdir\", temp_dir, input_path\n",
    "        ], check=True)\n",
    "        pdf_path = os.path.join(temp_dir, Path(input_path).with_suffix(\".pdf\").name)\n",
    "        return convert_from_path(pdf_path, dpi=dpi, output_folder=temp_dir, fmt=\"png\")\n",
    "    elif ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        return [Image.open(input_path).convert(\"RGB\")]\n",
    "    else:\n",
    "        raise ValueError(f\"ÏßÄÏõêÌïòÏßÄ ÏïäÎäî ÌååÏùº ÌòïÏãùÏûÖÎãàÎã§: {ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdd60e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_bbox_to_target(bbox, current_size, target_size):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    scale_x = target_size[0] / current_size[0]\n",
    "    scale_y = target_size[1] / current_size[1]\n",
    "    return [\n",
    "        int(x1 * scale_x),\n",
    "        int(y1 * scale_y),\n",
    "        int(x2 * scale_x),\n",
    "        int(y2 * scale_y)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d29a8d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR Ï†ïÌôïÎèÑ ÎÜíÏù¥Îäî Î∞©Ìñ•ÏúºÎ°ú ÏàòÏ†ï ÏöîÌï®\n",
    "def extract_text(image_pil, bbox): \n",
    "    x1, y1, x2, y2 = bbox\n",
    "    cropped = image_pil.crop((x1, y1, x2, y2))\n",
    "    return pytesseract.image_to_string(cropped, lang='kor+eng').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1067bb2",
   "metadata": {},
   "source": [
    "Ïù¥ Ìï®ÏàòÎäî Í∞úÏÑ†Ïù¥ ÌïÑÏöîÌï†Íπå?\n",
    "Ïù¥ Ìï®ÏàòÎäî ÌÖçÏä§Ìä∏ Ï∂îÏ∂úÏùò Í∏∞Î≥∏ Í∏∞Îä•ÏùÄ Ïûò ÏàòÌñâÌïòÍ≥† ÏûàÏäµÎãàÎã§. ÌïòÏßÄÎßå OCRÏùò Ï†ïÌôïÎèÑÎ•º ÎÜíÏù¥Î†§Î©¥ Îã§Ïùå Î∂ÄÎ∂ÑÏùÑ Í∞úÏÑ†Ìï† Ïàò ÏûàÏäµÎãàÎã§.\n",
    "\n",
    "Ìï¥ÏÉÅÎèÑ ÏµúÏ†ÅÌôî: convert_to_images Ìï®ÏàòÏóêÏÑú dpi Í∞íÏùÑ Ï°∞Ï†ïÌïòÎ©¥ OCR Ï†ïÌôïÎèÑÍ∞Ä Îã¨ÎùºÏßà Ïàò ÏûàÏäµÎãàÎã§. ÏòàÎ•º Îì§Ïñ¥, DPIÎ•º ÎÜíÏù¥Î©¥ Îçî ÏÑ†Î™ÖÌïú Ïù¥ÎØ∏ÏßÄÎ•º ÏñªÏñ¥ Ï†ïÌôïÎèÑÍ∞Ä ÎÜíÏïÑÏßÄÏßÄÎßå, Ï≤òÎ¶¨ ÏÜçÎèÑÍ∞Ä ÎäêÎ†§ÏßëÎãàÎã§.\n",
    "\n",
    "Ï†ÑÏ≤òÎ¶¨ Í∞ïÌôî: ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú Ï†ÑÏóê Ïù¥ÎØ∏ÏßÄÏùò ÎåÄÎπÑ(contrast)Î•º ÎÜíÏù¥Í±∞ÎÇò, ÎÖ∏Ïù¥Ï¶àÎ•º Ï†úÍ±∞ÌïòÎäî Îì±Ïùò Ï†ÑÏ≤òÎ¶¨ ÏûëÏóÖÏùÑ Ï∂îÍ∞ÄÌïòÎ©¥ OCR ÏÑ±Îä•Ïù¥ Îçî Ï¢ãÏïÑÏßà Ïàò ÏûàÏäµÎãàÎã§.\n",
    "\n",
    "Îã§Î•∏ OCR ÏóîÏßÑ ÏÇ¨Ïö©: pytesseract Ïô∏Ïóê EasyOCRÎÇò PaddleOCRÏôÄ Í∞ôÏùÄ Îã§Î•∏ OCR ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º ÏÇ¨Ïö©Ìï¥ Î≥¥ÏÑ∏Ïöî. Ïù¥Îì§ÏùÄ Í≤ΩÏö∞Ïóê Îî∞Îùº Îçî ÎÜíÏùÄ Ï†ïÌôïÎèÑÎ•º Ï†úÍ≥µÌï† Ïàò ÏûàÏäµÎãàÎã§.\n",
    "\n",
    "Í≤∞Î°†Ï†ÅÏúºÎ°ú, Ïù¥ Ìï®ÏàòÎäî ÌÖçÏä§Ìä∏ Ï∂îÏ∂úÏùò ÌïµÏã¨Ïù¥ÎØÄÎ°ú, OCR Ï†ïÌôïÎèÑÎ•º ÎÜíÏù¥Îäî Î∞©Ìñ•ÏúºÎ°ú Í∞úÏÑ†ÏùÑ Í≥†Î†§Ìï¥ Î≥º Ïàò ÏûàÏäµÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27cfb1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Í∞úÏÑ†\n",
    "def extract_equation_as_latex(image_pil, bbox):\n",
    "    try:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        cropped_image = image_pil.crop((x1, y1, x2, y2))\n",
    "        \n",
    "        # Pix2Tex Î™®Îç∏ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Ïù¥ÎØ∏ÏßÄÏóêÏÑú LaTeX ÏΩîÎìú Ï∂îÏ∂ú\n",
    "        latex_code = equation_model(cropped_image)\n",
    "        \n",
    "        return f'${latex_code}$'\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ÏàòÏãù Î≥ÄÌôò Ïã§Ìå®: {e}\")\n",
    "        return \"\" # Ïò§Î•ò Î∞úÏÉù Ïãú Îπà Î¨∏ÏûêÏó¥ Î∞òÌôò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2e6c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inference_one_image(id_val, image_pil, target_size, conf_thres=0.3):\n",
    "#     original_size = image_pil.size  # (w, h)\n",
    "#     resized_image = image_pil.resize((1024, 1024))\n",
    "#     temp_path = \"_temp_image.png\"\n",
    "#     resized_image.save(temp_path)\n",
    "\n",
    "#     results = model(source=temp_path, imgsz=1024, conf=conf_thres, verbose=False)[0]\n",
    "#     os.remove(temp_path)\n",
    "\n",
    "#     predictions = []\n",
    "#     order = 0\n",
    "#     for box, score, cls in zip(results.boxes.xyxy, results.boxes.conf, results.boxes.cls):\n",
    "#         label = results.names[int(cls)]\n",
    "#         if label not in LABEL_MAP:\n",
    "#             continue\n",
    "#         category_type = LABEL_MAP[label]\n",
    "#         x1, y1, x2, y2 = scale_bbox_to_target(box.tolist(), (1024, 1024), target_size)\n",
    "#         text = extract_text(image_pil, [x1, y1, x2, y2]) if category_type in ['title', 'subtitle', 'text'] else ''\n",
    "#         predictions.append({\n",
    "#             'ID': id_val,\n",
    "#             'category_type': category_type,\n",
    "#             'confidence_score': score.cpu().item(),\n",
    "#             'order': order,\n",
    "#             'text': text,\n",
    "#             'bbox': f'{x1}, {y1}, {x2}, {y2}'\n",
    "#         })\n",
    "#         order += 1\n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe2f223",
   "metadata": {},
   "source": [
    "ÎÑ§, Ïù¥ Ìï®ÏàòÎäî Í∞ÄÏû• ÎßéÏù¥ ÏàòÏ†ïÌïòÍ≥† Í∞úÏÑ†Ìï¥Ïïº Ìï† Î∂ÄÎ∂ÑÏûÖÎãàÎã§. ÌäπÌûà Îã§Ïùå Îëê Í∞ÄÏßÄÍ∞Ä ÌïµÏã¨ Í∞úÏÑ†Ï†êÏûÖÎãàÎã§.\n",
    "\n",
    "ÏàúÏÑú(order) ÏòàÏ∏° Î°úÏßÅ:\n",
    "\n",
    "ÌòÑÏû¨ ÏΩîÎìúÎäî order = 0ÏúºÎ°ú ÏãúÏûëÌïòÏó¨ Î£®ÌîÑÎ•º Îèå ÎïåÎßàÎã§ order += 1ÏùÑ Ìï©ÎãàÎã§. Ïù¥Îäî Î™®Îç∏Ïù¥ Í≤∞Í≥ºÎ•º Î∞òÌôòÌïú ÏàúÏÑúÎåÄÎ°ú ÏàúÏúÑÎ•º Îß§Í∏∞Îäî Í≤ÉÏúºÎ°ú, ÎÖºÎ¶¨Ï†ÅÏù∏ ÏùΩÍ∏∞ ÏàúÏÑúÏôÄÎäî ÏïÑÎ¨¥ Í¥ÄÎ†®Ïù¥ ÏóÜÏäµÎãàÎã§.\n",
    "\n",
    "Í∞úÏÑ† Î∞©Î≤ï: Î£®ÌîÑÍ∞Ä ÎÅùÎÇú ÌõÑ predictions Î¶¨Ïä§Ìä∏Î•º bbox Ï¢åÌëúÎ•º Í∏∞Ï§ÄÏúºÎ°ú Ïû¨Ï†ïÎ†¨ÌïòÎäî ÏÉàÎ°úÏö¥ Î°úÏßÅÏùÑ Ï∂îÍ∞ÄÌï¥Ïïº Ìï©ÎãàÎã§. ÏòàÎ•º Îì§Ïñ¥, y1 Ï¢åÌëúÎ•º Í∏∞Ï§ÄÏúºÎ°ú Ïò§Î¶ÑÏ∞®Ïàú Ï†ïÎ†¨ÌïòÍ≥†, y1Ïù¥ Í∞ôÏùÑ Í≤ΩÏö∞ x1ÏùÑ Í∏∞Ï§ÄÏúºÎ°ú Îã§Ïãú Ï†ïÎ†¨ÌïòÎäî Î∞©ÏãùÏù¥ Í∞ÄÏû• Í∏∞Î≥∏Ï†ÅÏûÖÎãàÎã§.\n",
    "\n",
    "ÏàòÏãù(equation) Ï∂îÏ∂ú:\n",
    "\n",
    "ÌòÑÏû¨ ÏΩîÎìúÏóêÎäî ÏàòÏãù(Formula)Ïù¥ category_typeÏúºÎ°úÎäî Ï°¥Ïû¨ÌïòÏßÄÎßå, textÎ•º Ï∂îÏ∂úÌïòÏßÄ ÏïäÏäµÎãàÎã§.\n",
    "\n",
    "Í∞úÏÑ† Î∞©Î≤ï: category_typeÏù¥ 'equation'Ïùº Îïå, textÎ•º Îπà Î¨∏ÏûêÏó¥('')Î°ú ÎëêÎäî ÎåÄÏã†, extract_text Ìï®ÏàòÏôÄÎäî Î≥ÑÍ∞úÎ°ú ÏàòÏãù Ïù¥ÎØ∏ÏßÄÎ•º LaTeXÎ°ú Î≥ÄÌôòÌïòÎäî ÏÉàÎ°úÏö¥ Ìï®ÏàòÎ•º Ìò∏Ï∂úÌïòÏó¨ Í≤∞Í≥ºÎ•º text ÌïÑÎìúÏóê Ï±ÑÏõå ÎÑ£Ïñ¥Ïïº Ìï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87beb165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Í∞úÏÑ†\n",
    "def inference_one_image_improved(id_val, image_pil, target_size, conf_thres=0.5):\n",
    "    original_size = image_pil.size\n",
    "    resized_image = image_pil.resize((1024, 1024))\n",
    "    temp_path = \"_temp_image.png\"\n",
    "    resized_image.save(temp_path)\n",
    "\n",
    "    results = yolo_model(source=temp_path, imgsz=1024, conf=conf_thres, verbose=False)[0]\n",
    "    os.remove(temp_path)\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    # 1. Î™®Îç∏ ÏòàÏ∏° Í≤∞Í≥ºÎ•º Î¶¨Ïä§Ìä∏Ïóê Ï†ÄÏû•\n",
    "    for box, score, cls in zip(results.boxes.xyxy, results.boxes.conf, results.boxes.cls):\n",
    "        label = results.names[int(cls)]\n",
    "        if label not in LABEL_MAP:\n",
    "            continue\n",
    "        category_type = LABEL_MAP[label]\n",
    "        bbox_scaled = scale_bbox_to_target(box.tolist(), (1024, 1024), target_size)\n",
    "        \n",
    "        # üí° Í∞úÏÑ†Îêú Î°úÏßÅ: category_typeÏóê Îî∞Îùº Ìïú Î≤àÎßå Ìò∏Ï∂ú\n",
    "        text = ''\n",
    "        if category_type in ['title', 'subtitle', 'text']:\n",
    "            text = extract_text(image_pil, bbox_scaled)\n",
    "        elif category_type == 'equation':\n",
    "            text = extract_equation_as_latex(image_pil, bbox_scaled, equation_model)\n",
    "        \n",
    "        predictions.append({\n",
    "            'ID': id_val,\n",
    "            'category_type': category_type,\n",
    "            'confidence_score': score.cpu().item(),\n",
    "            'bbox': f'{bbox_scaled[0]}, {bbox_scaled[1]}, {bbox_scaled[2]}, {bbox_scaled[3]}',\n",
    "            'bbox_list': bbox_scaled, \n",
    "            'text': text\n",
    "        })\n",
    "\n",
    "    # 2. Î∞îÏö¥Îî© Î∞ïÏä§ ÏúÑÏπòÎ•º Í∏∞Ï§ÄÏúºÎ°ú Ï†ïÎ†¨\n",
    "    predictions.sort(key=lambda p: (p['bbox_list'][1], p['bbox_list'][0]))\n",
    "    \n",
    "    # 3. Ï†ïÎ†¨Îêú Î¶¨Ïä§Ìä∏Ïóê 'order' Í∞í Î∂ÄÏó¨\n",
    "    for i, p in enumerate(predictions):\n",
    "        p['order'] = i\n",
    "        del p['bbox_list']\n",
    "        \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20051429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(test_csv_path=\"./data/test.csv\", output_csv_path=\"./output/submission.csv\"):\n",
    "    output_dir = os.path.dirname(output_csv_path)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    temp_image_dir = \"./temp_images\"\n",
    "    os.makedirs(temp_image_dir, exist_ok=True)\n",
    "\n",
    "    csv_dir = os.path.dirname(test_csv_path)\n",
    "    test_df = pd.read_csv(test_csv_path)\n",
    "    all_preds = []\n",
    "\n",
    "    for _, row in test_df.iterrows():\n",
    "        id_val = row['ID']\n",
    "        raw_path = row['path']\n",
    "        file_path = os.path.normpath(os.path.join(csv_dir, raw_path))\n",
    "        target_width = int(row['width'])\n",
    "        target_height = int(row['height'])\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"‚ö†Ô∏è ÌååÏùº ÏóÜÏùå: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            images = convert_to_images(file_path, temp_image_dir)\n",
    "            for i, image in enumerate(images):\n",
    "                full_id = f\"{id_val}_p{i+1}\" if len(images) > 1 else id_val\n",
    "                preds = inference_one_image_improved(full_id, image, (target_width, target_height))\n",
    "                all_preds.extend(preds)\n",
    "            print(f\"‚úÖ ÏòàÏ∏° ÏôÑÎ£å: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Ï≤òÎ¶¨ Ïã§Ìå®: {file_path} ‚Üí {e}\")\n",
    "\n",
    "    result_df = pd.DataFrame(all_preds)\n",
    "    result_df.to_csv(output_csv_path, index=False, encoding='UTF-8-sig')\n",
    "    print(f\"‚úÖ Ï†ÄÏû• ÏôÑÎ£å: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9afe1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    inference(\"./data/test.csv\", \"./output/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde3453-fabd-4b1e-a61f-eeb90f3bf4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon2025samsung",
   "language": "python",
   "name": "dacon2025samsung"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
