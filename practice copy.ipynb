{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35aa1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import subprocess\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5fcb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ìƒˆë¡­ê²Œ ì„¤ì¹˜í•´ì•¼ í•  ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "# pip install \"git+https://github.com/lucas-r/pix2tex.git\"\n",
    "from pix2tex.cli import LatexOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996725a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ë¡œë”©\n",
    "yolo_model = YOLO(\"./model/yolov11n-doclaynet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2438093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ìƒˆë¡œìš´ ëª¨ë¸\n",
    "equation_model = LatexOCR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37fefbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í´ë˜ìŠ¤ ë§¤í•‘\n",
    "LABEL_MAP = {\n",
    "    'Text': 'text',\n",
    "    'Title': 'title',\n",
    "    'Section-header': 'subtitle',\n",
    "    'Formula': 'equation',\n",
    "    'Table': 'table',\n",
    "    'Picture': 'image'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c008554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_images(input_path, temp_dir, dpi=200):\n",
    "    ext = Path(input_path).suffix.lower()\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    if ext == \".pdf\":\n",
    "        return convert_from_path(input_path, dpi=dpi, output_folder=temp_dir, fmt=\"png\")\n",
    "    elif ext == \".pptx\":\n",
    "        # Convert pptx to pdf first\n",
    "        subprocess.run([\n",
    "            \"libreoffice\", \"--headless\", \"--convert-to\", \"pdf\", \"--outdir\", temp_dir, input_path\n",
    "        ], check=True)\n",
    "        pdf_path = os.path.join(temp_dir, Path(input_path).with_suffix(\".pdf\").name)\n",
    "        return convert_from_path(pdf_path, dpi=dpi, output_folder=temp_dir, fmt=\"png\")\n",
    "    elif ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        return [Image.open(input_path).convert(\"RGB\")]\n",
    "    else:\n",
    "        raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdd60e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_bbox_to_target(bbox, current_size, target_size):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    scale_x = target_size[0] / current_size[0]\n",
    "    scale_y = target_size[1] / current_size[1]\n",
    "    return [\n",
    "        int(x1 * scale_x),\n",
    "        int(y1 * scale_y),\n",
    "        int(x2 * scale_x),\n",
    "        int(y2 * scale_y)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d29a8d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR ì •í™•ë„ ë†’ì´ëŠ” ë°©í–¥ìœ¼ë¡œ ìˆ˜ì • ìš”í•¨\n",
    "def extract_text(image_pil, bbox): \n",
    "    x1, y1, x2, y2 = bbox\n",
    "    cropped = image_pil.crop((x1, y1, x2, y2))\n",
    "    return pytesseract.image_to_string(cropped, lang='kor+eng').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1067bb2",
   "metadata": {},
   "source": [
    "ì´ í•¨ìˆ˜ëŠ” ê°œì„ ì´ í•„ìš”í• ê¹Œ?\n",
    "ì´ í•¨ìˆ˜ëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œì˜ ê¸°ë³¸ ê¸°ëŠ¥ì€ ì˜ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ OCRì˜ ì •í™•ë„ë¥¼ ë†’ì´ë ¤ë©´ ë‹¤ìŒ ë¶€ë¶„ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "í•´ìƒë„ ìµœì í™”: convert_to_images í•¨ìˆ˜ì—ì„œ dpi ê°’ì„ ì¡°ì •í•˜ë©´ OCR ì •í™•ë„ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, DPIë¥¼ ë†’ì´ë©´ ë” ì„ ëª…í•œ ì´ë¯¸ì§€ë¥¼ ì–»ì–´ ì •í™•ë„ê°€ ë†’ì•„ì§€ì§€ë§Œ, ì²˜ë¦¬ ì†ë„ê°€ ëŠë ¤ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "ì „ì²˜ë¦¬ ê°•í™”: í…ìŠ¤íŠ¸ ì¶”ì¶œ ì „ì— ì´ë¯¸ì§€ì˜ ëŒ€ë¹„(contrast)ë¥¼ ë†’ì´ê±°ë‚˜, ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ëŠ” ë“±ì˜ ì „ì²˜ë¦¬ ì‘ì—…ì„ ì¶”ê°€í•˜ë©´ OCR ì„±ëŠ¥ì´ ë” ì¢‹ì•„ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ë¥¸ OCR ì—”ì§„ ì‚¬ìš©: pytesseract ì™¸ì— EasyOCRë‚˜ PaddleOCRì™€ ê°™ì€ ë‹¤ë¥¸ OCR ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ ë³´ì„¸ìš”. ì´ë“¤ì€ ê²½ìš°ì— ë”°ë¼ ë” ë†’ì€ ì •í™•ë„ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê²°ë¡ ì ìœ¼ë¡œ, ì´ í•¨ìˆ˜ëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œì˜ í•µì‹¬ì´ë¯€ë¡œ, OCR ì •í™•ë„ë¥¼ ë†’ì´ëŠ” ë°©í–¥ìœ¼ë¡œ ê°œì„ ì„ ê³ ë ¤í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27cfb1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ê°œì„ \n",
    "def extract_equation_as_latex(image_pil, bbox):\n",
    "    try:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        cropped_image = image_pil.crop((x1, y1, x2, y2))\n",
    "        \n",
    "        # Pix2Tex ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ LaTeX ì½”ë“œ ì¶”ì¶œ\n",
    "        latex_code = equation_model(cropped_image)\n",
    "        \n",
    "        return f'${latex_code}$'\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ìˆ˜ì‹ ë³€í™˜ ì‹¤íŒ¨: {e}\")\n",
    "        return \"\" # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2e6c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inference_one_image(id_val, image_pil, target_size, conf_thres=0.3):\n",
    "#     original_size = image_pil.size  # (w, h)\n",
    "#     resized_image = image_pil.resize((1024, 1024))\n",
    "#     temp_path = \"_temp_image.png\"\n",
    "#     resized_image.save(temp_path)\n",
    "\n",
    "#     results = model(source=temp_path, imgsz=1024, conf=conf_thres, verbose=False)[0]\n",
    "#     os.remove(temp_path)\n",
    "\n",
    "#     predictions = []\n",
    "#     order = 0\n",
    "#     for box, score, cls in zip(results.boxes.xyxy, results.boxes.conf, results.boxes.cls):\n",
    "#         label = results.names[int(cls)]\n",
    "#         if label not in LABEL_MAP:\n",
    "#             continue\n",
    "#         category_type = LABEL_MAP[label]\n",
    "#         x1, y1, x2, y2 = scale_bbox_to_target(box.tolist(), (1024, 1024), target_size)\n",
    "#         text = extract_text(image_pil, [x1, y1, x2, y2]) if category_type in ['title', 'subtitle', 'text'] else ''\n",
    "#         predictions.append({\n",
    "#             'ID': id_val,\n",
    "#             'category_type': category_type,\n",
    "#             'confidence_score': score.cpu().item(),\n",
    "#             'order': order,\n",
    "#             'text': text,\n",
    "#             'bbox': f'{x1}, {y1}, {x2}, {y2}'\n",
    "#         })\n",
    "#         order += 1\n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe2f223",
   "metadata": {},
   "source": [
    "ë„¤, ì´ í•¨ìˆ˜ëŠ” ê°€ì¥ ë§ì´ ìˆ˜ì •í•˜ê³  ê°œì„ í•´ì•¼ í•  ë¶€ë¶„ì…ë‹ˆë‹¤. íŠ¹íˆ ë‹¤ìŒ ë‘ ê°€ì§€ê°€ í•µì‹¬ ê°œì„ ì ì…ë‹ˆë‹¤.\n",
    "\n",
    "ìˆœì„œ(order) ì˜ˆì¸¡ ë¡œì§:\n",
    "\n",
    "í˜„ì¬ ì½”ë“œëŠ” order = 0ìœ¼ë¡œ ì‹œì‘í•˜ì—¬ ë£¨í”„ë¥¼ ëŒ ë•Œë§ˆë‹¤ order += 1ì„ í•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ê²°ê³¼ë¥¼ ë°˜í™˜í•œ ìˆœì„œëŒ€ë¡œ ìˆœìœ„ë¥¼ ë§¤ê¸°ëŠ” ê²ƒìœ¼ë¡œ, ë…¼ë¦¬ì ì¸ ì½ê¸° ìˆœì„œì™€ëŠ” ì•„ë¬´ ê´€ë ¨ì´ ì—†ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê°œì„  ë°©ë²•: ë£¨í”„ê°€ ëë‚œ í›„ predictions ë¦¬ìŠ¤íŠ¸ë¥¼ bbox ì¢Œí‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¬ì •ë ¬í•˜ëŠ” ìƒˆë¡œìš´ ë¡œì§ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, y1 ì¢Œí‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬í•˜ê³ , y1ì´ ê°™ì„ ê²½ìš° x1ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ì‹œ ì •ë ¬í•˜ëŠ” ë°©ì‹ì´ ê°€ì¥ ê¸°ë³¸ì ì…ë‹ˆë‹¤.\n",
    "\n",
    "ìˆ˜ì‹(equation) ì¶”ì¶œ:\n",
    "\n",
    "í˜„ì¬ ì½”ë“œì—ëŠ” ìˆ˜ì‹(Formula)ì´ category_typeìœ¼ë¡œëŠ” ì¡´ì¬í•˜ì§€ë§Œ, textë¥¼ ì¶”ì¶œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê°œì„  ë°©ë²•: category_typeì´ 'equation'ì¼ ë•Œ, textë¥¼ ë¹ˆ ë¬¸ìì—´('')ë¡œ ë‘ëŠ” ëŒ€ì‹ , extract_text í•¨ìˆ˜ì™€ëŠ” ë³„ê°œë¡œ ìˆ˜ì‹ ì´ë¯¸ì§€ë¥¼ LaTeXë¡œ ë³€í™˜í•˜ëŠ” ìƒˆë¡œìš´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ë¥¼ text í•„ë“œì— ì±„ì›Œ ë„£ì–´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87beb165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ê°œì„ \n",
    "def inference_one_image_improved(id_val, image_pil, target_size, conf_thres=0.5):\n",
    "    original_size = image_pil.size\n",
    "    resized_image = image_pil.resize((1024, 1024))\n",
    "    temp_path = \"_temp_image.png\"\n",
    "    resized_image.save(temp_path)\n",
    "\n",
    "    results = yolo_model(source=temp_path, imgsz=1024, conf=conf_thres, verbose=False)[0]\n",
    "    os.remove(temp_path)\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    # 1. ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥\n",
    "    for box, score, cls in zip(results.boxes.xyxy, results.boxes.conf, results.boxes.cls):\n",
    "        label = results.names[int(cls)]\n",
    "        if label not in LABEL_MAP:\n",
    "            continue\n",
    "        category_type = LABEL_MAP[label]\n",
    "        bbox_scaled = scale_bbox_to_target(box.tolist(), (1024, 1024), target_size)\n",
    "        \n",
    "        # ğŸ’¡ ê°œì„ ëœ ë¡œì§: category_typeì— ë”°ë¼ í•œ ë²ˆë§Œ í˜¸ì¶œ\n",
    "        text = ''\n",
    "        if category_type in ['title', 'subtitle', 'text']:\n",
    "            text = extract_text(image_pil, bbox_scaled)\n",
    "        elif category_type == 'equation':\n",
    "            text = extract_equation_as_latex(image_pil, bbox_scaled, equation_model)\n",
    "        \n",
    "        predictions.append({\n",
    "            'ID': id_val,\n",
    "            'category_type': category_type,\n",
    "            'confidence_score': score.cpu().item(),\n",
    "            'bbox': f'{bbox_scaled[0]}, {bbox_scaled[1]}, {bbox_scaled[2]}, {bbox_scaled[3]}',\n",
    "            'bbox_list': bbox_scaled, \n",
    "            'text': text\n",
    "        })\n",
    "\n",
    "    # 2. ë°”ìš´ë”© ë°•ìŠ¤ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
    "    predictions.sort(key=lambda p: (p['bbox_list'][1], p['bbox_list'][0]))\n",
    "    \n",
    "    # 3. ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ì— 'order' ê°’ ë¶€ì—¬\n",
    "    for i, p in enumerate(predictions):\n",
    "        p['order'] = i\n",
    "        del p['bbox_list']\n",
    "        \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20051429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(test_csv_path=\"./data/test.csv\", output_csv_path=\"./output/submission.csv\"):\n",
    "    output_dir = os.path.dirname(output_csv_path)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    temp_image_dir = \"./temp_images\"\n",
    "    os.makedirs(temp_image_dir, exist_ok=True)\n",
    "\n",
    "    csv_dir = os.path.dirname(test_csv_path)\n",
    "    test_df = pd.read_csv(test_csv_path)\n",
    "    all_preds = []\n",
    "\n",
    "    for _, row in test_df.iterrows():\n",
    "        id_val = row['ID']\n",
    "        raw_path = row['path']\n",
    "        file_path = os.path.normpath(os.path.join(csv_dir, raw_path))\n",
    "        target_width = int(row['width'])\n",
    "        target_height = int(row['height'])\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"âš ï¸ íŒŒì¼ ì—†ìŒ: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            images = convert_to_images(file_path, temp_image_dir)\n",
    "            for i, image in enumerate(images):\n",
    "                full_id = f\"{id_val}_p{i+1}\" if len(images) > 1 else id_val\n",
    "                preds = inference_one_image_improved(full_id, image, (target_width, target_height))\n",
    "                all_preds.extend(preds)\n",
    "            print(f\"âœ… ì˜ˆì¸¡ ì™„ë£Œ: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {file_path} â†’ {e}\")\n",
    "\n",
    "    result_df = pd.DataFrame(all_preds)\n",
    "    result_df.to_csv(output_csv_path, index=False, encoding='UTF-8-sig')\n",
    "    print(f\"âœ… ì €ì¥ ì™„ë£Œ: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9afe1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert /mnt/c/Users/user/documents/dacon2025samsung/data/test/TEST_00.pptx -> /mnt/c/Users/user/documents/dacon2025samsung/temp_images/TEST_00.pdf using filter : impress_pdf_Export\n",
      "âœ… ì˜ˆì¸¡ ì™„ë£Œ: data/test/TEST_00.pptx\n",
      "âœ… ì˜ˆì¸¡ ì™„ë£Œ: data/test/TEST_01.png\n",
      "âœ… ì˜ˆì¸¡ ì™„ë£Œ: data/test/TEST_02.pdf\n",
      "âœ… ì˜ˆì¸¡ ì™„ë£Œ: data/test/TEST_03.jpg\n",
      "âœ… ì €ì¥ ì™„ë£Œ: ./output/submission.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    inference(\"./data/test.csv\", \"./output/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d2ab015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ë°ì´ì½˜ í‰ê°€ ì‚°ì‹ ì½”ë“œ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# ------------------------- ê¸°ë³¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ -------------------------\n",
    "def parse_bbox(bbox_str):\n",
    "    \"\"\"bbox íŒŒì‹±\"\"\"\n",
    "    if isinstance(bbox_str, str):\n",
    "        return list(map(float, bbox_str.replace(' ', '').split(',')))\n",
    "    elif isinstance(bbox_str, list):\n",
    "        return bbox_str\n",
    "    else:\n",
    "        raise ValueError(f\"bbox í˜•ì‹ ì˜¤ë¥˜: {bbox_str}\")\n",
    "\n",
    "def iou(boxA, boxB):\n",
    "    \"\"\"IoU ê³„ì‚°\"\"\"\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    inter = max(0, xB - xA) * max(0, yB - yA)\n",
    "    if inter == 0: \n",
    "        return 0.0\n",
    "    areaA = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    areaB = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "    return inter / (areaA + areaB - inter)\n",
    "\n",
    "def normalized_edit_distance(s1, s2):\n",
    "    \"\"\"ì •ê·œí™”ëœ í¸ì§‘ ê±°ë¦¬ (NED)\"\"\"\n",
    "    s1, s2 = str(s1).strip(), str(s2).strip()\n",
    "    max_len = max(len(s1), len(s2))\n",
    "    return 0.0 if max_len == 0 else 1 - SequenceMatcher(None, s1, s2).ratio()\n",
    "\n",
    "def ned_reading_order(gt_list, pred_list):\n",
    "    \"\"\"Reading Order NED ê³„ì‚°\"\"\"\n",
    "    if not gt_list and not pred_list:\n",
    "        return 0.0\n",
    "    if not gt_list or not pred_list:\n",
    "        return 1.0\n",
    "    if len(gt_list) < 2 or len(pred_list) < 2:\n",
    "        return 1.0 if gt_list != pred_list else 0.0\n",
    "    gt_str = ','.join(map(str, gt_list))\n",
    "    pred_str = ','.join(map(str, pred_list))\n",
    "    return 1 - SequenceMatcher(None, gt_str, pred_str).ratio()\n",
    "\n",
    "# ------------------------- COCO-style mAP@0.5:0.95 ê³„ì‚° -------------------------\n",
    "def compute_custom_map(answer_df, pred_df):\n",
    "    \"\"\"\n",
    "    COCO-style mAP ê³„ì‚° - ì™„ì „ ê°œì„ ëœ ë²„ì „\n",
    "    ì˜ˆì¸¡ë ¥ì´ ë‚˜ì˜ê±°ë‚˜ ë°ì´í„°ê°€ ì—†ì–´ë„ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™\n",
    "    \"\"\"\n",
    "    IOU_THRESHOLDS = np.arange(0.5, 1.0, 0.05)\n",
    "    CATEGORIES = sorted(answer_df['category_type'].unique())\n",
    "    ap_all = []\n",
    "\n",
    "    for category in CATEGORIES:\n",
    "        gt_cat = answer_df[answer_df['category_type'] == category].copy()\n",
    "        pred_cat = pred_df[pred_df['category_type'] == category].copy()\n",
    "\n",
    "        # GTê°€ ì—†ìœ¼ë©´ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ëª¨ë“  IoU thresholdì—ì„œ AP = 0\n",
    "        if len(gt_cat) == 0:\n",
    "            for _ in IOU_THRESHOLDS:\n",
    "                ap_all.append(0.0)\n",
    "            continue\n",
    "\n",
    "        gt_by_image = gt_cat.groupby('ID')\n",
    "        pred_by_image = pred_cat.groupby('ID')\n",
    "\n",
    "        for iou_thresh in IOU_THRESHOLDS:\n",
    "            tps, fps = [], []\n",
    "            total_gts = 0\n",
    "\n",
    "            for doc_id, gt_group in gt_by_image:\n",
    "                try:\n",
    "                    gt_boxes = gt_group['bbox'].apply(parse_bbox).tolist()\n",
    "                    matched = [False] * len(gt_boxes)\n",
    "                    total_gts += len(gt_boxes)\n",
    "\n",
    "                    # ì˜ˆì¸¡ ë°ì´í„° ì²˜ë¦¬\n",
    "                    if doc_id in pred_by_image.groups:\n",
    "                        pred_group = pred_by_image.get_group(doc_id)\n",
    "                        pred_boxes = pred_group[['bbox', 'confidence_score']].copy()\n",
    "                        pred_boxes['bbox'] = pred_boxes['bbox'].apply(parse_bbox)\n",
    "                        # Confidence score ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (COCO í‘œì¤€)\n",
    "                        pred_boxes = pred_boxes.sort_values('confidence_score', ascending=False).reset_index(drop=True)\n",
    "                    else:\n",
    "                        pred_boxes = pd.DataFrame(columns=['bbox', 'confidence_score'])\n",
    "\n",
    "                    # ê° ì˜ˆì¸¡ì— ëŒ€í•´ TP/FP íŒì •\n",
    "                    for _, row in pred_boxes.iterrows():\n",
    "                        pred_box = row['bbox']\n",
    "                        matched_flag = False\n",
    "                        for i, gt_box in enumerate(gt_boxes):\n",
    "                            if not matched[i] and iou(pred_box, gt_box) >= iou_thresh:\n",
    "                                matched[i] = True\n",
    "                                matched_flag = True\n",
    "                                break\n",
    "                        if matched_flag:\n",
    "                            tps.append(1)\n",
    "                            fps.append(0)\n",
    "                        else:\n",
    "                            tps.append(0)\n",
    "                            fps.append(1)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"ë¬¸ì„œ {doc_id} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # ì „ì²´ GTê°€ 0ì¸ ê²½ìš° AP = 0\n",
    "            if total_gts == 0:\n",
    "                ap_all.append(0.0)\n",
    "                continue\n",
    "\n",
    "            # ì˜ˆì¸¡ì´ ì•„ì˜ˆ ì—†ëŠ” ê²½ìš° AP = 0\n",
    "            if len(tps) == 0:\n",
    "                ap_all.append(0.0)\n",
    "                continue\n",
    "\n",
    "            tps = np.array(tps)\n",
    "            fps = np.array(fps)\n",
    "            cum_tp = np.cumsum(tps)\n",
    "            cum_fp = np.cumsum(fps)\n",
    "            \n",
    "            # Precisionê³¼ Recall ê³„ì‚°\n",
    "            precisions = cum_tp / (cum_tp + cum_fp + 1e-6)\n",
    "            recalls = cum_tp / (total_gts + 1e-6)\n",
    "\n",
    "            # recallsê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° ì²˜ë¦¬ (ì¶”ê°€ ì•ˆì „ì¥ì¹˜)\n",
    "            if len(recalls) == 0:\n",
    "                ap_all.append(0.0)\n",
    "                continue\n",
    "\n",
    "            # Monotonic precision ê³„ì‚° ë° 101-point interpolation\n",
    "            precisions = np.maximum.accumulate(precisions[::-1])[::-1]\n",
    "            recall_points = np.linspace(0, 1, 101)\n",
    "            \n",
    "            try:\n",
    "                interp_precisions = np.interp(recall_points, recalls, precisions, left=0, right=0)\n",
    "                ap = np.mean(interp_precisions)\n",
    "                ap_all.append(ap)\n",
    "            except Exception as e:\n",
    "                print(f\"ì¹´í…Œê³ ë¦¬ {category}, IoU {iou_thresh:.2f}: interpolation ì˜¤ë¥˜ - {e}\")\n",
    "                ap_all.append(0.0)\n",
    "\n",
    "    return np.mean(ap_all) if ap_all else 0.0\n",
    "\n",
    "# ------------------------- OCR & Reading Order í‰ê°€ -------------------------\n",
    "def process_document(args):\n",
    "    \"\"\"ë¬¸ì„œë³„ OCR ë° Reading Order í‰ê°€\"\"\"\n",
    "    doc_id, answer_df, pred_df = args\n",
    "    OCR_CATS = {'title', 'subtitle', 'text'}\n",
    "    RO_CATS = {'title', 'subtitle', 'text', 'image', 'table', 'equation'}\n",
    "\n",
    "    gt_items = answer_df[answer_df['ID'] == doc_id].copy()\n",
    "    pred_items = pred_df[pred_df['ID'] == doc_id].copy()\n",
    "    \n",
    "    # ë¹ˆ ë°ì´í„° ì²˜ë¦¬\n",
    "    if len(gt_items) == 0:\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    try:\n",
    "        gt_items['bbox'] = gt_items['bbox'].apply(parse_bbox)\n",
    "        pred_items['bbox'] = pred_items['bbox'].apply(parse_bbox)\n",
    "    except Exception as e:\n",
    "        print(f\"ë¬¸ì„œ {doc_id} bbox íŒŒì‹± ì˜¤ë¥˜: {e}\")\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    matched_gt, matched_pred = set(), set()\n",
    "    ocr_dist, ro_pairs = [], []\n",
    "\n",
    "    # GT ê¸°ì¤€ìœ¼ë¡œ 1:1 ë§¤ì¹­\n",
    "    for i, gt in gt_items.iterrows():\n",
    "        # order ì»¬ëŸ¼ ìœ íš¨ì„± ê²€ì‚¬\n",
    "        gt_order = gt.get('order', None)\n",
    "        if pd.isna(gt_order):\n",
    "            gt_order = None\n",
    "            \n",
    "        best_iou, best_j = 0, -1\n",
    "        for j, pred in pred_items.iterrows():\n",
    "            if j in matched_pred or gt['category_type'] != pred['category_type']:\n",
    "                continue\n",
    "                \n",
    "            iou_val = iou(gt['bbox'], pred['bbox'])\n",
    "            if iou_val >= 0.5 and iou_val > best_iou:\n",
    "                best_iou, best_j = iou_val, j\n",
    "                \n",
    "        if best_j != -1:\n",
    "            matched_gt.add(i)\n",
    "            matched_pred.add(best_j)\n",
    "            pred = pred_items.loc[best_j]\n",
    "            \n",
    "            # OCR í‰ê°€\n",
    "            if gt['category_type'] in OCR_CATS:\n",
    "                gt_text = gt.get('text', '')\n",
    "                pred_text = pred.get('text', '')\n",
    "                ocr_dist.append(normalized_edit_distance(gt_text, pred_text))\n",
    "            \n",
    "            # Reading Order í‰ê°€ - order ìœ íš¨ì„± ê²€ì‚¬\n",
    "            if gt['category_type'] in RO_CATS and gt_order is not None:\n",
    "                pred_order = pred.get('order', None)\n",
    "                if not pd.isna(pred_order):\n",
    "                    ro_pairs.append((gt_order, pred_order))\n",
    "        else:\n",
    "            # ë§¤ì¹­ ì‹¤íŒ¨ì‹œ OCR ì ìˆ˜ 1.0 ì¶”ê°€ (ìµœëŒ€ íŒ¨ë„í‹°)\n",
    "            if gt['category_type'] in OCR_CATS:\n",
    "                ocr_dist.append(1.0)\n",
    "\n",
    "    # OCR ì ìˆ˜ ê³„ì‚°\n",
    "    ocr_score = 1 - np.mean(ocr_dist) if ocr_dist else 0.0\n",
    "    \n",
    "    # Reading Order ì ìˆ˜ ê³„ì‚° - NaN ë°©ì§€ ê°•í™”\n",
    "    if ro_pairs and len(ro_pairs) > 0:\n",
    "        try:\n",
    "            ro_pairs.sort(key=lambda x: x[0])  # GT order ê¸°ì¤€ ì •ë ¬\n",
    "            gt_seq = [g for g, _ in ro_pairs]\n",
    "            pred_seq = [p for _, p in ro_pairs]\n",
    "            \n",
    "            # NaN ì²´í¬\n",
    "            if any(pd.isna(x) for x in gt_seq + pred_seq):\n",
    "                ro_score = 0.0\n",
    "            else:\n",
    "                ned = ned_reading_order(gt_seq, pred_seq)\n",
    "                \n",
    "                # Coverage ê³„ì‚° - 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€\n",
    "                ro_eligible_items = gt_items[gt_items['category_type'].isin(RO_CATS)]\n",
    "                if len(ro_eligible_items) > 0:\n",
    "                    coverage = len(ro_pairs) / len(ro_eligible_items)\n",
    "                    ro_score = (1 - ned) * coverage\n",
    "                else:\n",
    "                    ro_score = 0.0\n",
    "        except Exception as e:\n",
    "            print(f\"ë¬¸ì„œ {doc_id} Reading Order ê³„ì‚° ì˜¤ë¥˜: {e}\")\n",
    "            ro_score = 0.0\n",
    "    else:\n",
    "        ro_score = 0.0\n",
    "\n",
    "    return ocr_score, ro_score\n",
    "\n",
    "# ------------------------- ìµœì¢… í‰ê°€ í•¨ìˆ˜ -------------------------\n",
    "def evaluate_document(answer_df, pred_df):\n",
    "    \"\"\"\n",
    "    OmniDocBench ìŠ¤íƒ€ì¼ ë¬¸ì„œ í‰ê°€\n",
    "    - OCR (NED): 30%\n",
    "    - Layout Detection (mAP@0.5:0.95): 35%\n",
    "    - Reading Order (NED): 35%\n",
    "    \"\"\"\n",
    "    ALLOWED_CATEGORIES = {'title', 'subtitle', 'text', 'image', 'table', 'equation'}\n",
    "    \n",
    "    # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬\n",
    "    if len(answer_df) == 0 or len(pred_df) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸\n",
    "    required_cols_answer = ['ID', 'category_type', 'order', 'text', 'bbox']\n",
    "    required_cols_pred = ['ID', 'category_type', 'confidence_score', 'order', 'text', 'bbox']\n",
    "    \n",
    "    for col in required_cols_answer:\n",
    "        if col not in answer_df.columns:\n",
    "            raise ValueError(f\"Answer ë°ì´í„°ì— '{col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    for col in required_cols_pred:\n",
    "        if col not in pred_df.columns:\n",
    "            raise ValueError(f\"Prediction ë°ì´í„°ì— '{col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ì¹´í…Œê³ ë¦¬ í•„í„°ë§\n",
    "    answer_df = answer_df[answer_df['category_type'].isin(ALLOWED_CATEGORIES)].copy()\n",
    "    pred_df = pred_df[pred_df['category_type'].isin(ALLOWED_CATEGORIES)].copy()\n",
    "\n",
    "    # ë³‘ë ¬ ì²˜ë¦¬ë¡œ OCR ë° Reading Order í‰ê°€\n",
    "    n_processes = min(cpu_count(), 4)  # ìµœëŒ€ 4ê°œ í”„ë¡œì„¸ìŠ¤\n",
    "    tasks = [(doc_id, answer_df, pred_df) for doc_id in answer_df['ID'].unique()]\n",
    "\n",
    "    try:\n",
    "        with Pool(n_processes) as pool:\n",
    "            results = pool.map(process_document, tasks)\n",
    "    except Exception as e:\n",
    "        results = [process_document(task) for task in tasks]\n",
    "\n",
    "    # ê²°ê³¼ ì§‘ê³„ - NaN ë°©ì§€ ë¡œì§ ê°•í™”\n",
    "    if results:\n",
    "        ocr_scores, ro_scores = zip(*results)\n",
    "        \n",
    "        # OCR ì ìˆ˜ ê³„ì‚° - NaN í•„í„°ë§\n",
    "        valid_ocr_scores = [s for s in ocr_scores if not pd.isna(s)]\n",
    "        ocr_score = np.mean(valid_ocr_scores) if valid_ocr_scores else 0.0\n",
    "        \n",
    "        # Reading Order ì ìˆ˜ ê³„ì‚° - í•µì‹¬ ìˆ˜ì •: 0.0ë„ ìœ íš¨í•œ ì ìˆ˜ë¡œ í¬í•¨\n",
    "        valid_ro_scores = [s for s in ro_scores if not pd.isna(s)]\n",
    "        reading_order_score = np.mean(valid_ro_scores) if valid_ro_scores else 0.0\n",
    "            \n",
    "    else:\n",
    "        ocr_score = 0.0\n",
    "        reading_order_score = 0.0\n",
    "\n",
    "    # Layout Detection í‰ê°€\n",
    "    layout_score = compute_custom_map(answer_df, pred_df)\n",
    "\n",
    "    # ìµœì¢… ì ìˆ˜ ê³„ì‚° - NaN ì²´í¬ ë° ì¹˜í™˜\n",
    "    scores = [ocr_score, layout_score, reading_order_score]\n",
    "    if any(pd.isna(s) for s in scores):\n",
    "        ocr_score = 0.0 if pd.isna(ocr_score) else ocr_score\n",
    "        layout_score = 0.0 if pd.isna(layout_score) else layout_score\n",
    "        reading_order_score = 0.0 if pd.isna(reading_order_score) else reading_order_score\n",
    "    \n",
    "    final_score = 0.30 * ocr_score + 0.35 * layout_score + 0.35 * reading_order_score\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1867dfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': \"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: [Errno 2] No such file or directory: './data/ground_truth.csv'\"}\n"
     ]
    }
   ],
   "source": [
    "# --- ì‚¬ìš© ì˜ˆì‹œ ---\n",
    "# # 'ground_truth.csv' íŒŒì¼ì´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "submission_file = \"./output/submission.csv\"\n",
    "ground_truth_file = \"./data/ground_truth.csv\" \n",
    "final_result = evaluate_submission(submission_file, ground_truth_file)\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde3453-fabd-4b1e-a61f-eeb90f3bf4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon2025samsung",
   "language": "python",
   "name": "dacon2025samsung"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
