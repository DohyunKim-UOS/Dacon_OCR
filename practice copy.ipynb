{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35aa1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import subprocess\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5fcb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#새롭게 설치해야 할 라이브러리\n",
    "# pip install \"git+https://github.com/lucas-r/pix2tex.git\"\n",
    "from pix2tex.cli import LatexOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996725a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로딩\n",
    "yolo_model = YOLO(\"./model/yolov11n-doclaynet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2438093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#새로운 모델\n",
    "equation_model = LatexOCR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37fefbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 매핑\n",
    "LABEL_MAP = {\n",
    "    'Text': 'text',\n",
    "    'Title': 'title',\n",
    "    'Section-header': 'subtitle',\n",
    "    'Formula': 'equation',\n",
    "    'Table': 'table',\n",
    "    'Picture': 'image'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c008554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_images(input_path, temp_dir, dpi=200):\n",
    "    ext = Path(input_path).suffix.lower()\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    if ext == \".pdf\":\n",
    "        return convert_from_path(input_path, dpi=dpi, output_folder=temp_dir, fmt=\"png\")\n",
    "    elif ext == \".pptx\":\n",
    "        # Convert pptx to pdf first\n",
    "        subprocess.run([\n",
    "            \"libreoffice\", \"--headless\", \"--convert-to\", \"pdf\", \"--outdir\", temp_dir, input_path\n",
    "        ], check=True)\n",
    "        pdf_path = os.path.join(temp_dir, Path(input_path).with_suffix(\".pdf\").name)\n",
    "        return convert_from_path(pdf_path, dpi=dpi, output_folder=temp_dir, fmt=\"png\")\n",
    "    elif ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        return [Image.open(input_path).convert(\"RGB\")]\n",
    "    else:\n",
    "        raise ValueError(f\"지원하지 않는 파일 형식입니다: {ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdd60e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_bbox_to_target(bbox, current_size, target_size):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    scale_x = target_size[0] / current_size[0]\n",
    "    scale_y = target_size[1] / current_size[1]\n",
    "    return [\n",
    "        int(x1 * scale_x),\n",
    "        int(y1 * scale_y),\n",
    "        int(x2 * scale_x),\n",
    "        int(y2 * scale_y)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d29a8d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR 정확도 높이는 방향으로 수정 요함\n",
    "def extract_text(image_pil, bbox): \n",
    "    x1, y1, x2, y2 = bbox\n",
    "    cropped = image_pil.crop((x1, y1, x2, y2))\n",
    "    return pytesseract.image_to_string(cropped, lang='kor+eng').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1067bb2",
   "metadata": {},
   "source": [
    "이 함수는 개선이 필요할까?\n",
    "이 함수는 텍스트 추출의 기본 기능은 잘 수행하고 있습니다. 하지만 OCR의 정확도를 높이려면 다음 부분을 개선할 수 있습니다.\n",
    "\n",
    "해상도 최적화: convert_to_images 함수에서 dpi 값을 조정하면 OCR 정확도가 달라질 수 있습니다. 예를 들어, DPI를 높이면 더 선명한 이미지를 얻어 정확도가 높아지지만, 처리 속도가 느려집니다.\n",
    "\n",
    "전처리 강화: 텍스트 추출 전에 이미지의 대비(contrast)를 높이거나, 노이즈를 제거하는 등의 전처리 작업을 추가하면 OCR 성능이 더 좋아질 수 있습니다.\n",
    "\n",
    "다른 OCR 엔진 사용: pytesseract 외에 EasyOCR나 PaddleOCR와 같은 다른 OCR 라이브러리를 사용해 보세요. 이들은 경우에 따라 더 높은 정확도를 제공할 수 있습니다.\n",
    "\n",
    "결론적으로, 이 함수는 텍스트 추출의 핵심이므로, OCR 정확도를 높이는 방향으로 개선을 고려해 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27cfb1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#개선\n",
    "def extract_equation_as_latex(image_pil, bbox):\n",
    "    try:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        cropped_image = image_pil.crop((x1, y1, x2, y2))\n",
    "        \n",
    "        # Pix2Tex 모델을 사용하여 이미지에서 LaTeX 코드 추출\n",
    "        latex_code = equation_model(cropped_image)\n",
    "        \n",
    "        return f'${latex_code}$'\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"수식 변환 실패: {e}\")\n",
    "        return \"\" # 오류 발생 시 빈 문자열 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2e6c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inference_one_image(id_val, image_pil, target_size, conf_thres=0.3):\n",
    "#     original_size = image_pil.size  # (w, h)\n",
    "#     resized_image = image_pil.resize((1024, 1024))\n",
    "#     temp_path = \"_temp_image.png\"\n",
    "#     resized_image.save(temp_path)\n",
    "\n",
    "#     results = model(source=temp_path, imgsz=1024, conf=conf_thres, verbose=False)[0]\n",
    "#     os.remove(temp_path)\n",
    "\n",
    "#     predictions = []\n",
    "#     order = 0\n",
    "#     for box, score, cls in zip(results.boxes.xyxy, results.boxes.conf, results.boxes.cls):\n",
    "#         label = results.names[int(cls)]\n",
    "#         if label not in LABEL_MAP:\n",
    "#             continue\n",
    "#         category_type = LABEL_MAP[label]\n",
    "#         x1, y1, x2, y2 = scale_bbox_to_target(box.tolist(), (1024, 1024), target_size)\n",
    "#         text = extract_text(image_pil, [x1, y1, x2, y2]) if category_type in ['title', 'subtitle', 'text'] else ''\n",
    "#         predictions.append({\n",
    "#             'ID': id_val,\n",
    "#             'category_type': category_type,\n",
    "#             'confidence_score': score.cpu().item(),\n",
    "#             'order': order,\n",
    "#             'text': text,\n",
    "#             'bbox': f'{x1}, {y1}, {x2}, {y2}'\n",
    "#         })\n",
    "#         order += 1\n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe2f223",
   "metadata": {},
   "source": [
    "네, 이 함수는 가장 많이 수정하고 개선해야 할 부분입니다. 특히 다음 두 가지가 핵심 개선점입니다.\n",
    "\n",
    "순서(order) 예측 로직:\n",
    "\n",
    "현재 코드는 order = 0으로 시작하여 루프를 돌 때마다 order += 1을 합니다. 이는 모델이 결과를 반환한 순서대로 순위를 매기는 것으로, 논리적인 읽기 순서와는 아무 관련이 없습니다.\n",
    "\n",
    "개선 방법: 루프가 끝난 후 predictions 리스트를 bbox 좌표를 기준으로 재정렬하는 새로운 로직을 추가해야 합니다. 예를 들어, y1 좌표를 기준으로 오름차순 정렬하고, y1이 같을 경우 x1을 기준으로 다시 정렬하는 방식이 가장 기본적입니다.\n",
    "\n",
    "수식(equation) 추출:\n",
    "\n",
    "현재 코드에는 수식(Formula)이 category_type으로는 존재하지만, text를 추출하지 않습니다.\n",
    "\n",
    "개선 방법: category_type이 'equation'일 때, text를 빈 문자열('')로 두는 대신, extract_text 함수와는 별개로 수식 이미지를 LaTeX로 변환하는 새로운 함수를 호출하여 결과를 text 필드에 채워 넣어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87beb165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#개선\n",
    "def inference_one_image_improved(id_val, image_pil, target_size, conf_thres=0.5):\n",
    "    original_size = image_pil.size\n",
    "    resized_image = image_pil.resize((1024, 1024))\n",
    "    temp_path = \"_temp_image.png\"\n",
    "    resized_image.save(temp_path)\n",
    "\n",
    "    results = yolo_model(source=temp_path, imgsz=1024, conf=conf_thres, verbose=False)[0]\n",
    "    os.remove(temp_path)\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    # 1. 모델 예측 결과를 리스트에 저장\n",
    "    for box, score, cls in zip(results.boxes.xyxy, results.boxes.conf, results.boxes.cls):\n",
    "        label = results.names[int(cls)]\n",
    "        if label not in LABEL_MAP:\n",
    "            continue\n",
    "        category_type = LABEL_MAP[label]\n",
    "        bbox_scaled = scale_bbox_to_target(box.tolist(), (1024, 1024), target_size)\n",
    "        \n",
    "        # 💡 개선된 로직: category_type에 따라 한 번만 호출\n",
    "        text = ''\n",
    "        if category_type in ['title', 'subtitle', 'text']:\n",
    "            text = extract_text(image_pil, bbox_scaled)\n",
    "        elif category_type == 'equation':\n",
    "            text = extract_equation_as_latex(image_pil, bbox_scaled, equation_model)\n",
    "        \n",
    "        predictions.append({\n",
    "            'ID': id_val,\n",
    "            'category_type': category_type,\n",
    "            'confidence_score': score.cpu().item(),\n",
    "            'bbox': f'{bbox_scaled[0]}, {bbox_scaled[1]}, {bbox_scaled[2]}, {bbox_scaled[3]}',\n",
    "            'bbox_list': bbox_scaled, \n",
    "            'text': text\n",
    "        })\n",
    "\n",
    "    # 2. 바운딩 박스 위치를 기준으로 정렬\n",
    "    predictions.sort(key=lambda p: (p['bbox_list'][1], p['bbox_list'][0]))\n",
    "    \n",
    "    # 3. 정렬된 리스트에 'order' 값 부여\n",
    "    for i, p in enumerate(predictions):\n",
    "        p['order'] = i\n",
    "        del p['bbox_list']\n",
    "        \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20051429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(test_csv_path=\"./data/test.csv\", output_csv_path=\"./output/submission.csv\"):\n",
    "    output_dir = os.path.dirname(output_csv_path)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    temp_image_dir = \"./temp_images\"\n",
    "    os.makedirs(temp_image_dir, exist_ok=True)\n",
    "\n",
    "    csv_dir = os.path.dirname(test_csv_path)\n",
    "    test_df = pd.read_csv(test_csv_path)\n",
    "    all_preds = []\n",
    "\n",
    "    for _, row in test_df.iterrows():\n",
    "        id_val = row['ID']\n",
    "        raw_path = row['path']\n",
    "        file_path = os.path.normpath(os.path.join(csv_dir, raw_path))\n",
    "        target_width = int(row['width'])\n",
    "        target_height = int(row['height'])\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"⚠️ 파일 없음: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            images = convert_to_images(file_path, temp_image_dir)\n",
    "            for i, image in enumerate(images):\n",
    "                full_id = f\"{id_val}_p{i+1}\" if len(images) > 1 else id_val\n",
    "                preds = inference_one_image_improved(full_id, image, (target_width, target_height))\n",
    "                all_preds.extend(preds)\n",
    "            print(f\"✅ 예측 완료: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 처리 실패: {file_path} → {e}\")\n",
    "\n",
    "    result_df = pd.DataFrame(all_preds)\n",
    "    result_df.to_csv(output_csv_path, index=False, encoding='UTF-8-sig')\n",
    "    print(f\"✅ 저장 완료: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9afe1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert /mnt/c/Users/user/documents/dacon2025samsung/data/test/TEST_00.pptx -> /mnt/c/Users/user/documents/dacon2025samsung/temp_images/TEST_00.pdf using filter : impress_pdf_Export\n",
      "✅ 예측 완료: data/test/TEST_00.pptx\n",
      "✅ 예측 완료: data/test/TEST_01.png\n",
      "✅ 예측 완료: data/test/TEST_02.pdf\n",
      "✅ 예측 완료: data/test/TEST_03.jpg\n",
      "✅ 저장 완료: ./output/submission.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    inference(\"./data/test.csv\", \"./output/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d2ab015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이콘 평가 산식 코드\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# ------------------------- 기본 유틸리티 함수 -------------------------\n",
    "def parse_bbox(bbox_str):\n",
    "    \"\"\"bbox 파싱\"\"\"\n",
    "    if isinstance(bbox_str, str):\n",
    "        return list(map(float, bbox_str.replace(' ', '').split(',')))\n",
    "    elif isinstance(bbox_str, list):\n",
    "        return bbox_str\n",
    "    else:\n",
    "        raise ValueError(f\"bbox 형식 오류: {bbox_str}\")\n",
    "\n",
    "def iou(boxA, boxB):\n",
    "    \"\"\"IoU 계산\"\"\"\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    inter = max(0, xB - xA) * max(0, yB - yA)\n",
    "    if inter == 0: \n",
    "        return 0.0\n",
    "    areaA = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    areaB = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "    return inter / (areaA + areaB - inter)\n",
    "\n",
    "def normalized_edit_distance(s1, s2):\n",
    "    \"\"\"정규화된 편집 거리 (NED)\"\"\"\n",
    "    s1, s2 = str(s1).strip(), str(s2).strip()\n",
    "    max_len = max(len(s1), len(s2))\n",
    "    return 0.0 if max_len == 0 else 1 - SequenceMatcher(None, s1, s2).ratio()\n",
    "\n",
    "def ned_reading_order(gt_list, pred_list):\n",
    "    \"\"\"Reading Order NED 계산\"\"\"\n",
    "    if not gt_list and not pred_list:\n",
    "        return 0.0\n",
    "    if not gt_list or not pred_list:\n",
    "        return 1.0\n",
    "    if len(gt_list) < 2 or len(pred_list) < 2:\n",
    "        return 1.0 if gt_list != pred_list else 0.0\n",
    "    gt_str = ','.join(map(str, gt_list))\n",
    "    pred_str = ','.join(map(str, pred_list))\n",
    "    return 1 - SequenceMatcher(None, gt_str, pred_str).ratio()\n",
    "\n",
    "# ------------------------- COCO-style mAP@0.5:0.95 계산 -------------------------\n",
    "def compute_custom_map(answer_df, pred_df):\n",
    "    \"\"\"\n",
    "    COCO-style mAP 계산 - 완전 개선된 버전\n",
    "    예측력이 나쁘거나 데이터가 없어도 안정적으로 작동\n",
    "    \"\"\"\n",
    "    IOU_THRESHOLDS = np.arange(0.5, 1.0, 0.05)\n",
    "    CATEGORIES = sorted(answer_df['category_type'].unique())\n",
    "    ap_all = []\n",
    "\n",
    "    for category in CATEGORIES:\n",
    "        gt_cat = answer_df[answer_df['category_type'] == category].copy()\n",
    "        pred_cat = pred_df[pred_df['category_type'] == category].copy()\n",
    "\n",
    "        # GT가 없으면 해당 카테고리의 모든 IoU threshold에서 AP = 0\n",
    "        if len(gt_cat) == 0:\n",
    "            for _ in IOU_THRESHOLDS:\n",
    "                ap_all.append(0.0)\n",
    "            continue\n",
    "\n",
    "        gt_by_image = gt_cat.groupby('ID')\n",
    "        pred_by_image = pred_cat.groupby('ID')\n",
    "\n",
    "        for iou_thresh in IOU_THRESHOLDS:\n",
    "            tps, fps = [], []\n",
    "            total_gts = 0\n",
    "\n",
    "            for doc_id, gt_group in gt_by_image:\n",
    "                try:\n",
    "                    gt_boxes = gt_group['bbox'].apply(parse_bbox).tolist()\n",
    "                    matched = [False] * len(gt_boxes)\n",
    "                    total_gts += len(gt_boxes)\n",
    "\n",
    "                    # 예측 데이터 처리\n",
    "                    if doc_id in pred_by_image.groups:\n",
    "                        pred_group = pred_by_image.get_group(doc_id)\n",
    "                        pred_boxes = pred_group[['bbox', 'confidence_score']].copy()\n",
    "                        pred_boxes['bbox'] = pred_boxes['bbox'].apply(parse_bbox)\n",
    "                        # Confidence score 기준 내림차순 정렬 (COCO 표준)\n",
    "                        pred_boxes = pred_boxes.sort_values('confidence_score', ascending=False).reset_index(drop=True)\n",
    "                    else:\n",
    "                        pred_boxes = pd.DataFrame(columns=['bbox', 'confidence_score'])\n",
    "\n",
    "                    # 각 예측에 대해 TP/FP 판정\n",
    "                    for _, row in pred_boxes.iterrows():\n",
    "                        pred_box = row['bbox']\n",
    "                        matched_flag = False\n",
    "                        for i, gt_box in enumerate(gt_boxes):\n",
    "                            if not matched[i] and iou(pred_box, gt_box) >= iou_thresh:\n",
    "                                matched[i] = True\n",
    "                                matched_flag = True\n",
    "                                break\n",
    "                        if matched_flag:\n",
    "                            tps.append(1)\n",
    "                            fps.append(0)\n",
    "                        else:\n",
    "                            tps.append(0)\n",
    "                            fps.append(1)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"문서 {doc_id} 처리 중 오류: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # 전체 GT가 0인 경우 AP = 0\n",
    "            if total_gts == 0:\n",
    "                ap_all.append(0.0)\n",
    "                continue\n",
    "\n",
    "            # 예측이 아예 없는 경우 AP = 0\n",
    "            if len(tps) == 0:\n",
    "                ap_all.append(0.0)\n",
    "                continue\n",
    "\n",
    "            tps = np.array(tps)\n",
    "            fps = np.array(fps)\n",
    "            cum_tp = np.cumsum(tps)\n",
    "            cum_fp = np.cumsum(fps)\n",
    "            \n",
    "            # Precision과 Recall 계산\n",
    "            precisions = cum_tp / (cum_tp + cum_fp + 1e-6)\n",
    "            recalls = cum_tp / (total_gts + 1e-6)\n",
    "\n",
    "            # recalls가 비어있는 경우 처리 (추가 안전장치)\n",
    "            if len(recalls) == 0:\n",
    "                ap_all.append(0.0)\n",
    "                continue\n",
    "\n",
    "            # Monotonic precision 계산 및 101-point interpolation\n",
    "            precisions = np.maximum.accumulate(precisions[::-1])[::-1]\n",
    "            recall_points = np.linspace(0, 1, 101)\n",
    "            \n",
    "            try:\n",
    "                interp_precisions = np.interp(recall_points, recalls, precisions, left=0, right=0)\n",
    "                ap = np.mean(interp_precisions)\n",
    "                ap_all.append(ap)\n",
    "            except Exception as e:\n",
    "                print(f\"카테고리 {category}, IoU {iou_thresh:.2f}: interpolation 오류 - {e}\")\n",
    "                ap_all.append(0.0)\n",
    "\n",
    "    return np.mean(ap_all) if ap_all else 0.0\n",
    "\n",
    "# ------------------------- OCR & Reading Order 평가 -------------------------\n",
    "def process_document(args):\n",
    "    \"\"\"문서별 OCR 및 Reading Order 평가\"\"\"\n",
    "    doc_id, answer_df, pred_df = args\n",
    "    OCR_CATS = {'title', 'subtitle', 'text'}\n",
    "    RO_CATS = {'title', 'subtitle', 'text', 'image', 'table', 'equation'}\n",
    "\n",
    "    gt_items = answer_df[answer_df['ID'] == doc_id].copy()\n",
    "    pred_items = pred_df[pred_df['ID'] == doc_id].copy()\n",
    "    \n",
    "    # 빈 데이터 처리\n",
    "    if len(gt_items) == 0:\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    try:\n",
    "        gt_items['bbox'] = gt_items['bbox'].apply(parse_bbox)\n",
    "        pred_items['bbox'] = pred_items['bbox'].apply(parse_bbox)\n",
    "    except Exception as e:\n",
    "        print(f\"문서 {doc_id} bbox 파싱 오류: {e}\")\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    matched_gt, matched_pred = set(), set()\n",
    "    ocr_dist, ro_pairs = [], []\n",
    "\n",
    "    # GT 기준으로 1:1 매칭\n",
    "    for i, gt in gt_items.iterrows():\n",
    "        # order 컬럼 유효성 검사\n",
    "        gt_order = gt.get('order', None)\n",
    "        if pd.isna(gt_order):\n",
    "            gt_order = None\n",
    "            \n",
    "        best_iou, best_j = 0, -1\n",
    "        for j, pred in pred_items.iterrows():\n",
    "            if j in matched_pred or gt['category_type'] != pred['category_type']:\n",
    "                continue\n",
    "                \n",
    "            iou_val = iou(gt['bbox'], pred['bbox'])\n",
    "            if iou_val >= 0.5 and iou_val > best_iou:\n",
    "                best_iou, best_j = iou_val, j\n",
    "                \n",
    "        if best_j != -1:\n",
    "            matched_gt.add(i)\n",
    "            matched_pred.add(best_j)\n",
    "            pred = pred_items.loc[best_j]\n",
    "            \n",
    "            # OCR 평가\n",
    "            if gt['category_type'] in OCR_CATS:\n",
    "                gt_text = gt.get('text', '')\n",
    "                pred_text = pred.get('text', '')\n",
    "                ocr_dist.append(normalized_edit_distance(gt_text, pred_text))\n",
    "            \n",
    "            # Reading Order 평가 - order 유효성 검사\n",
    "            if gt['category_type'] in RO_CATS and gt_order is not None:\n",
    "                pred_order = pred.get('order', None)\n",
    "                if not pd.isna(pred_order):\n",
    "                    ro_pairs.append((gt_order, pred_order))\n",
    "        else:\n",
    "            # 매칭 실패시 OCR 점수 1.0 추가 (최대 패널티)\n",
    "            if gt['category_type'] in OCR_CATS:\n",
    "                ocr_dist.append(1.0)\n",
    "\n",
    "    # OCR 점수 계산\n",
    "    ocr_score = 1 - np.mean(ocr_dist) if ocr_dist else 0.0\n",
    "    \n",
    "    # Reading Order 점수 계산 - NaN 방지 강화\n",
    "    if ro_pairs and len(ro_pairs) > 0:\n",
    "        try:\n",
    "            ro_pairs.sort(key=lambda x: x[0])  # GT order 기준 정렬\n",
    "            gt_seq = [g for g, _ in ro_pairs]\n",
    "            pred_seq = [p for _, p in ro_pairs]\n",
    "            \n",
    "            # NaN 체크\n",
    "            if any(pd.isna(x) for x in gt_seq + pred_seq):\n",
    "                ro_score = 0.0\n",
    "            else:\n",
    "                ned = ned_reading_order(gt_seq, pred_seq)\n",
    "                \n",
    "                # Coverage 계산 - 0으로 나누기 방지\n",
    "                ro_eligible_items = gt_items[gt_items['category_type'].isin(RO_CATS)]\n",
    "                if len(ro_eligible_items) > 0:\n",
    "                    coverage = len(ro_pairs) / len(ro_eligible_items)\n",
    "                    ro_score = (1 - ned) * coverage\n",
    "                else:\n",
    "                    ro_score = 0.0\n",
    "        except Exception as e:\n",
    "            print(f\"문서 {doc_id} Reading Order 계산 오류: {e}\")\n",
    "            ro_score = 0.0\n",
    "    else:\n",
    "        ro_score = 0.0\n",
    "\n",
    "    return ocr_score, ro_score\n",
    "\n",
    "# ------------------------- 최종 평가 함수 -------------------------\n",
    "def evaluate_document(answer_df, pred_df):\n",
    "    \"\"\"\n",
    "    OmniDocBench 스타일 문서 평가\n",
    "    - OCR (NED): 30%\n",
    "    - Layout Detection (mAP@0.5:0.95): 35%\n",
    "    - Reading Order (NED): 35%\n",
    "    \"\"\"\n",
    "    ALLOWED_CATEGORIES = {'title', 'subtitle', 'text', 'image', 'table', 'equation'}\n",
    "    \n",
    "    # 데이터 유효성 검사\n",
    "    if len(answer_df) == 0 or len(pred_df) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # 필수 컬럼 확인\n",
    "    required_cols_answer = ['ID', 'category_type', 'order', 'text', 'bbox']\n",
    "    required_cols_pred = ['ID', 'category_type', 'confidence_score', 'order', 'text', 'bbox']\n",
    "    \n",
    "    for col in required_cols_answer:\n",
    "        if col not in answer_df.columns:\n",
    "            raise ValueError(f\"Answer 데이터에 '{col}' 컬럼이 없습니다.\")\n",
    "    \n",
    "    for col in required_cols_pred:\n",
    "        if col not in pred_df.columns:\n",
    "            raise ValueError(f\"Prediction 데이터에 '{col}' 컬럼이 없습니다.\")\n",
    "    \n",
    "    # 카테고리 필터링\n",
    "    answer_df = answer_df[answer_df['category_type'].isin(ALLOWED_CATEGORIES)].copy()\n",
    "    pred_df = pred_df[pred_df['category_type'].isin(ALLOWED_CATEGORIES)].copy()\n",
    "\n",
    "    # 병렬 처리로 OCR 및 Reading Order 평가\n",
    "    n_processes = min(cpu_count(), 4)  # 최대 4개 프로세스\n",
    "    tasks = [(doc_id, answer_df, pred_df) for doc_id in answer_df['ID'].unique()]\n",
    "\n",
    "    try:\n",
    "        with Pool(n_processes) as pool:\n",
    "            results = pool.map(process_document, tasks)\n",
    "    except Exception as e:\n",
    "        results = [process_document(task) for task in tasks]\n",
    "\n",
    "    # 결과 집계 - NaN 방지 로직 강화\n",
    "    if results:\n",
    "        ocr_scores, ro_scores = zip(*results)\n",
    "        \n",
    "        # OCR 점수 계산 - NaN 필터링\n",
    "        valid_ocr_scores = [s for s in ocr_scores if not pd.isna(s)]\n",
    "        ocr_score = np.mean(valid_ocr_scores) if valid_ocr_scores else 0.0\n",
    "        \n",
    "        # Reading Order 점수 계산 - 핵심 수정: 0.0도 유효한 점수로 포함\n",
    "        valid_ro_scores = [s for s in ro_scores if not pd.isna(s)]\n",
    "        reading_order_score = np.mean(valid_ro_scores) if valid_ro_scores else 0.0\n",
    "            \n",
    "    else:\n",
    "        ocr_score = 0.0\n",
    "        reading_order_score = 0.0\n",
    "\n",
    "    # Layout Detection 평가\n",
    "    layout_score = compute_custom_map(answer_df, pred_df)\n",
    "\n",
    "    # 최종 점수 계산 - NaN 체크 및 치환\n",
    "    scores = [ocr_score, layout_score, reading_order_score]\n",
    "    if any(pd.isna(s) for s in scores):\n",
    "        ocr_score = 0.0 if pd.isna(ocr_score) else ocr_score\n",
    "        layout_score = 0.0 if pd.isna(layout_score) else layout_score\n",
    "        reading_order_score = 0.0 if pd.isna(reading_order_score) else reading_order_score\n",
    "    \n",
    "    final_score = 0.30 * ocr_score + 0.35 * layout_score + 0.35 * reading_order_score\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1867dfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': \"파일을 찾을 수 없습니다: [Errno 2] No such file or directory: './data/ground_truth.csv'\"}\n"
     ]
    }
   ],
   "source": [
    "# --- 사용 예시 ---\n",
    "# # 'ground_truth.csv' 파일이 있다고 가정합니다.\n",
    "submission_file = \"./output/submission.csv\"\n",
    "ground_truth_file = \"./data/ground_truth.csv\" \n",
    "final_result = evaluate_submission(submission_file, ground_truth_file)\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde3453-fabd-4b1e-a61f-eeb90f3bf4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon2025samsung",
   "language": "python",
   "name": "dacon2025samsung"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
